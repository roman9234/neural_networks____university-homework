{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb93457",
   "metadata": {},
   "source": [
    "## Методические указания по выполнению лабораторной работы №3\n",
    "\n",
    "**Тема: Обнаружение объектов с использованием Faster R-CNN**\n",
    "\n",
    "**Цель работы:** Ознакомиться с архитектурой Faster R-CNN и принципами двухэтапного обнаружения объектов.\n",
    "\n",
    "**Задачи:**\n",
    "- Изучить теоретические основы двухэтапного обнаружения объектов: роль RPN и классификационного этапа в Faster R-CNN.\n",
    "- Загрузить предобученную модель Faster R-CNN.\n",
    "- Ознакомиться с форматом аннотаций для обучения в задаче детекции.\n",
    "- Визуализировать предсказания, проанализировать ошибки модели и провести исследование по поиску баланса FN/FP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931204b",
   "metadata": {},
   "source": [
    "### 1. Теоретическая часть\n",
    "\n",
    "В данной лабораторной работе мы познакомимся с задачей детекции на примере архитектуры [Faster R-CNN](https://arxiv.org/pdf/1506.01497), обученной на наборе данных [COCO](https://cocodataset.org/#home), а также с новым форматом данных для обучения нейро-сетевых моделей детекции. Для оценки модели воспользуемся набором данных [Pascal VOC 2007](http://host.robots.ox.ac.uk/pascal/VOC/).\n",
    "\n",
    "**Перед тем, как приступать к выполнению практической части, ознакомьтесь с первоисточниками используемых компонентов, а также документацией по [ссылке](https://pytorch.org/vision/master/models/faster_rcnn.html), включающей подробности работы с моделью и новым форматом данных, сэмплы кода.**\n",
    "\n",
    "#### 1.1 Архитектура Faster R-CNN\n",
    "\n",
    "Существует два основных подхода к обнаружению объектов:\n",
    "Двухстадийные модели – более точные, но медленные.\n",
    "Одностадийные модели – быстрые, но менее точные.\n",
    "\n",
    "Faster R-CNN — это двухэтапная модель детекции объектов. В отличие от ResNeXt, Faster R-CNN не просто классифицирует изображение, а находит на нём несколько объектов, предсказывает bounding boxes и присваивает метки классам. Она состоит из следующих компонентов:\n",
    "\n",
    "1. Backbone (ResNet/VGG/MobileNet) – извлекает признаки из изображения.\n",
    "2. Region Proposal Network (RPN) – предлагает области, где могут находиться объекты.\n",
    "3. ROI Pooling + Fully Connected Layers – классифицирует объекты и уточняет bounding boxes.\n",
    "4. Non-Maximum Suppression (NMS) – убирает дублирующиеся предсказания.\n",
    "\n",
    "\n",
    "В предыдущих лабораторных работах мы познакомились с классификацией изображений, где модель предсказывает единственный класс для всего изображения. Однако во многих задачах компьютерного зрения классификация недостаточна. Например, когда на одном изображении присутствуют несколько объектов разных классов необходимо не только определить, что изображено, но и где это находится.\n",
    "\n",
    "Faster R-CNN –  модель, которая также решает задачу обнаружения объектов, добавляя к классификации локализацию. \n",
    "\n",
    "#### 1.2 Формат данных для задачи детекции\n",
    "\n",
    "Faster R-CNN требует разметки изображений, помимо классов включающей в себя и координаты bounding box по оси x, y.\n",
    "Ознакомьтесь с форматом набора данных Pascal VOC, скачайте аннотации набора данных и изучите структуру **.xml** файлов в папке Annotations по [ссылке](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtestnoimgs_06-Nov-2007.tar).\n",
    "\n",
    "#### 1.3 Оценка качества\n",
    "\n",
    "Помимо известных вам инструментов оценить качество работы детектора могут помочь:\n",
    "\n",
    "Confidence Score - значение, указывающее на уверенность модели в том, что на данном месте изображения находится объект. Модель предсказывает этот параметр для каждого предсказанного bounding box. Чем выше confidence score, тем более уверена модель в своём предсказании.\n",
    "\n",
    "Фильтрация предсказаний - модель может предсказать много объектов, но не все из них будут точными. Чтобы уменьшить количество ложных срабатываний (False Positives), применяется фильтр предсказаний, используя confidence threshold. Если confidence score меньше заданного порога - предсказание отбрасывается.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f91f75c",
   "metadata": {},
   "source": [
    "### 2. Практическая часть\n",
    "\n",
    "#### 2.1 Подготовка окружения\n",
    "\n",
    "Установите зависимости и библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт пакетов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8ad59",
   "metadata": {},
   "source": [
    "#### 2.2 Подготовка модели\n",
    "\n",
    "Загрузите предобученную модель, определите устройство, переведите модель в режим инференса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ffb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2bcad1",
   "metadata": {},
   "source": [
    "#### 2.3 Загрузка и предобработка изображений\n",
    "\n",
    "\n",
    "Затем импортируйте датасет из соответствующих пакетов PyTorch и определите метод трансформации данных для подачи в модель. Он понадобится позже для преобразования изображений при прямом проходе через модель чтобы получить предсказания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка датасета\n",
    "\n",
    "# метод трансформации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd27810",
   "metadata": {},
   "source": [
    "#### 2.4 Объявление методов для работы с данными\n",
    "\n",
    "Далее необходимо создать методы препроцессинга: метод чтения файла аннотации для возврата numpy-объекта содержащего bounding boxes, и метод отрисовки истиных и прогнозных bounding boxes на изображении для визуализации полученных результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_voc_annotation(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    boxes = []\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin, ymin, xmax, ymax = (int(bbox.find(\"xmin\").text), int(bbox.find(\"ymin\").text),\n",
    "                                  int(bbox.find(\"xmax\").text), int(bbox.find(\"ymax\").text))\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "    return np.array(boxes)\n",
    "\n",
    "def draw_predictions(image, boxes, labels, scores, color=\"blue\"):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        xmin, ymin, xmax, ymax = map(int, box)\n",
    "        draw.rectangle([xmin, ymin, xmax, ymax], outline=color, width=2)\n",
    "        draw.text((xmin, ymin), f\"{label} ({score:.2f})\", fill=color)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60f68a",
   "metadata": {},
   "source": [
    "#### 2.5 Анализ False Positives / False Negatives\n",
    "\n",
    "Для измерения того, насколько хорошо bounding box предсказан, применяется параметр IoU (Intersection over Union) между двумя bounding boxes. Чем он выше, тем точнее предсказание. Для его оценки опишем следующий метод, принимающий два np.array-объекта (прогнозные и истинные координаты):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de59854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(pred_box, gt_box):\n",
    "    x1, y1, x2, y2 = pred_box\n",
    "    x1g, y1g, x2g, y2g = gt_box\n",
    "    \n",
    "    xi1 = max(x1, x1g)\n",
    "    yi1 = max(y1, y1g)\n",
    "    xi2 = min(x2, x2g)\n",
    "    yi2 = min(y2, y2g)\n",
    "\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2g - x1g) * (y2g - y1g)\n",
    "\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fccf59",
   "metadata": {},
   "source": [
    "#### 2.6 Оценка модели и визуализация результатов\n",
    "\n",
    "Выполните прямой проход нескольких изображений через модель. Для этого необходимо загрузить изображения и аннотации, применить преобразование изображений в тензор. Затем получите выходы модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выберите N изображений 5 из датасета\n",
    "image_filenames = [voc_dataset[i][1]['annotation']['filename'] for i in range(N)]\n",
    "\n",
    "# объявите цикл для проверки\n",
    "\n",
    "    # загрузите изображение и его разметку\n",
    "\n",
    "    # примените трансформации\n",
    "\n",
    "    # выполните прямой проход\n",
    "\n",
    "    # извлекаем bounding boxes, метки и confidence scores из полученных выходов модели\n",
    "    pred_boxes = outputs[0]['boxes'].cpu().numpy()\n",
    "    pred_labels = outputs[0]['labels'].cpu().numpy()\n",
    "    pred_scores = outputs[0]['scores'].cpu().numpy()\n",
    "\n",
    "    # установите порог confidence_threshold в эмпирическом значении\n",
    "    confidence_threshold = 0.5\n",
    "\n",
    "    # примените фильтр выходных значений на основе заданного порога\n",
    "\n",
    "    # отрисуйте bounding boxes на изображении с предсказаниями\n",
    "\n",
    "    # отрисуйте bounding boxes с реальной разметкой\n",
    "\n",
    "    # вычислите IoU для выбранных изображений\n",
    "    \n",
    "    # подсчитайте количество False Positive и False Negative для выбранных изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b119dba",
   "metadata": {},
   "source": [
    "#### 2.7 Поиск оптимальной конфигурации \n",
    "\n",
    "Проанализируйте полученные результаты с выбранным значением фильтрации предсказаний. Проведите исследование с целью поиска оптимального порога и баланса FN/FP. Обоснуйте полученные результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исследование\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
