{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb93457",
   "metadata": {},
   "source": [
    "## Методические указания по выполнению лабораторной работы №4\n",
    "\n",
    "**Тема: Сегментация объектов с использованием Mask R-CNN**\n",
    "\n",
    "**Цель работы:** Познакомиться с архитектурой Mask R-CNN и научиться выполнять сегментацию объектов на изображениях.\n",
    "\n",
    "**Задачи:**\n",
    "\n",
    "- Изучить теоретические основы instance segmentation.\n",
    "- Ознакомиться с архитектурой Mask R-CNN.\n",
    "- Провести инференс предобученной модели на выбранных изображениях.\n",
    "- Визуализировать результаты: bounding boxes, маски объектов.\n",
    "- Рассчитать метрики оценки качества масок.\n",
    "- Проанализировать ошибки сегментации.\n",
    "- Провести исследование зависимости качества от параметров confidence score и mask threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931204b",
   "metadata": {},
   "source": [
    "### 1. Теоретическая часть\n",
    "\n",
    "В данной лабораторной работе мы познакомимся с задачей детекции на примере архитектуры [Mask R-CNN](https://arxiv.org/pdf/1703.06870), обученной на наборе данных [COCO](https://cocodataset.org/#home), а также с новой задачей компьютерного зрения - сегментацией. \n",
    "\n",
    "**Перед тем, как приступать к выполнению практической части, ознакомьтесь с первоисточниками используемых компонентов, а также документацией по [ссылке](https://pytorch.org/vision/main/models/mask_rcnn.html), включающей подробности работы с моделью и новым форматом данных, сэмплы кода.**\n",
    "\n",
    "#### 1.1 Instance Segmentation и архитектура Mask R-CNN\n",
    "\n",
    "Instance segmentation — это задача, в которой необходимо не только обнаружить объект и его класс, но и сегментировать его границы на уровне пикселей. Это усложнённая версия задачи детекции, так как bounding box не всегда точно соответствует форме объекта.\n",
    "\n",
    "В отличие от semantic segmentation, где модель выдает одну маску на класс, в instance segmentation выделяется каждый объект независимо, даже если они относятся к одному классу.\n",
    "\n",
    "Mask R-CNN — это расширение Faster R-CNN, дополненное ещё одним выходом: бинарной маской для каждого обнаруженного объекта.\n",
    "\n",
    "Архитектура Mask R-CNN включает:\n",
    "\n",
    "1. Backbone (например, ResNet-50) — извлекает карты признаков из изображения.\n",
    "2. Region Proposal Network (RPN) — предлагает кандидаты на объекты.\n",
    "3. ROI Align / ROI Pooling — извлекает фиксированные области из фичей.\n",
    "4. Bounding Box Head — классифицирует объект и уточняет координаты.\n",
    "5. Mask Head — предсказывает маску для каждого класса, соответствующую bounding box.\n",
    "\n",
    "\n",
    "#### 1.2 Формат данных для задачи детекции\n",
    "\n",
    "При запуске инференса модель возвращает словарь с результатами: координаты bounding boxes, классы объектов, confidence score и маски объектов (представлены как float значения от 0 до 1).\n",
    "\n",
    "В рамках выполнения работы в зависимости от варианта вам предстоит познакомиться с другими форматами файлов и их содержимым.\n",
    "\n",
    "### Варианты \n",
    "\n",
    "Выполните задание в соответствии со своим вариантом по списку с использованием предобученной модели. \n",
    "\n",
    "**Вариант 1  - Pascal VOC 2007. Сравнить предсказания модели с реальной разметкой и провести количественную оценку:**\n",
    "\n",
    "- Выполнить инференс модели на 20 изображениях;\n",
    "- Визуализировать bounding boxes и маски;\n",
    "- Проанализировать качество предсказаний;\n",
    "- Описать, какие классы модель распознала, какие пропустила.\n",
    "\n",
    "**Вариант 2 — COCO 2017. Сравнить предсказания модели с реальной разметкой и провести количественную оценку:**\n",
    "\n",
    "- Выполнить инференс на 20 изображениях;\n",
    "- Визуализировать предсказания;\n",
    "- Сравнить полученные маски с ground truth;\n",
    "- Рассчитать IoU, Pixel Accuracy или Precision/Recall; \n",
    "\n",
    "**Вариант 3 — Cityscapes. Проверить, как модель работает на новых изображениях, визуализировать предсказания и сравнить с известными аннотациями:**\n",
    "\n",
    "- Выполнить инференс на 20 изображениях;\n",
    "- Визуализировать предсказания; \n",
    "- Сравнить полученные маски с ground truth;\n",
    "- Рассчитать IoU, Pixel Accuracy или Precision/Recall;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f91f75c",
   "metadata": {},
   "source": [
    "### 2. Практическая часть\n",
    "\n",
    "#### 2.1 Подготовка окружения\n",
    "\n",
    "Установите зависимости и библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт пакетов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8ad59",
   "metadata": {},
   "source": [
    "#### 2.2 Подготовка модели\n",
    "\n",
    "Загрузите предобученную модель, определите устройство, переведите модель в режим инференса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ffb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2bcad1",
   "metadata": {},
   "source": [
    "#### 2.3 Загрузка и предобработка изображений\n",
    "\n",
    "\n",
    "Затем импортируйте датасет из соответствующих пакетов PyTorch и определите метод трансформации данных для подачи в модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка датасета\n",
    "\n",
    "# метод трансформации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd27810",
   "metadata": {},
   "source": [
    "#### 2.4 Предсказания и извлечение масок\n",
    "\n",
    "Если вы работаете с Pascal VOC, вам потребуется прочитать файлы, содержащие разметку. Если вы работаете с COCO или Cityscapes, аннотации читаются через готовые методы COCO API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# методы извлечения меток и визуализации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60f68a",
   "metadata": {},
   "source": [
    "#### 2.5 Оценка модели и визуализация результатов\n",
    "\n",
    "Визуализируйте bounding box, название класса, маску поверх изображения. Для каждой маски и её соответствующего ground truth (если имеется), вычислите: IoU, количество FP пикселей, количество FN пикселей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de59854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инференс\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b119dba",
   "metadata": {},
   "source": [
    "#### 2.6 Исследование параметров маски и confidence\n",
    "\n",
    "Проведите серию экспериментов: протестируйте разные значения mask_threshold (0.3, 0.5, 0.7), протестируйте разные значения confidence_threshold, найдите оптимальное значение, при котором достигается лучший баланс между точностью и полнотой:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исследование\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
